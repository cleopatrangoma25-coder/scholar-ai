{"version":3,"sources":["../src/index.ts","../src/vertex-ai.ts","../src/workflows.ts"],"sourcesContent":["// Export all GCP clients\r\nexport * from \"./vertex-ai\";\r\nexport * from \"./workflows\"; ","import { PredictionServiceClient } from \"@google-cloud/aiplatform\";\r\nimport { RagQueryInput, RagResponse, Source } from \"@scholar-ai/shared\";\r\n\r\nexport class VertexAIClient {\r\n  private client: PredictionServiceClient;\r\n  private projectId: string;\r\n  private location: string;\r\n  private endpoint: string;\r\n\r\n  constructor(projectId: string, location: string = \"us-central1\") {\r\n    this.client = new PredictionServiceClient();\r\n    this.projectId = projectId;\r\n    this.location = location;\r\n    this.endpoint = `projects/${projectId}/locations/${location}`;\r\n  }\r\n\r\n  /**\r\n   * Query the RAG engine with a natural language question\r\n   */\r\n  async queryRAG(input: RagQueryInput): Promise<RagResponse> {\r\n    try {\r\n      console.log(`Querying RAG engine with: \"${input.query}\" (scope: ${input.scope})`);\r\n\r\n      // 1. Generate embeddings for the query\r\n      const queryEmbedding = await this.generateEmbedding(input.query);\r\n      \r\n      // 2. Search across the specified data stores\r\n      const dataStores = this.getDataStoresForScope(input.scope);\r\n      const searchResults = await this.searchVectorStore(queryEmbedding, dataStores);\r\n      \r\n      // 3. Retrieve relevant chunks and prepare context\r\n      const context = this.prepareContext(searchResults);\r\n      \r\n      // 4. Augment prompt with context and call Gemini\r\n      const answer = await this.generateAnswer(input.query, context, searchResults);\r\n      \r\n      // 5. Format sources from search results\r\n      const sources = this.formatSources(searchResults);\r\n\r\n      return {\r\n        answer,\r\n        sources,\r\n      };\r\n    } catch (error) {\r\n      console.error(\"Error querying RAG engine:\", error);\r\n      throw new Error(\"Failed to query RAG engine\");\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generate text embeddings using Vertex AI\r\n   */\r\n  private async generateEmbedding(text: string): Promise<number[]> {\r\n    try {\r\n      const model = \"text-embedding-gecko@003\";\r\n      const endpoint = `${this.endpoint}/publishers/google/models/${model}`;\r\n      \r\n      const request = {\r\n        endpoint,\r\n        instances: [\r\n          {\r\n            structValue: {\r\n              fields: {\r\n                content: {\r\n                  stringValue: text\r\n                }\r\n              }\r\n            }\r\n          }\r\n        ],\r\n      };\r\n\r\n      const [response] = await this.client.predict(request);\r\n      const prediction = response.predictions?.[0];\r\n      \r\n      if (!prediction || !prediction.structValue?.fields?.embeddings?.structValue?.fields?.values?.listValue?.values) {\r\n        throw new Error(\"Failed to generate embedding\");\r\n      }\r\n\r\n      const embeddingValues = prediction.structValue.fields.embeddings.structValue.fields.values.listValue.values;\r\n      return embeddingValues.map((value: any) => value.numberValue || 0);\r\n\r\n    } catch (error) {\r\n      console.error(\"Error generating embedding:\", error);\r\n      throw new Error(\"Failed to generate text embedding\");\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Search Vertex AI Vector Search for relevant documents\r\n   */\r\n  private async searchVectorStore(\r\n    queryEmbedding: number[], \r\n    dataStoreIds: string[]\r\n  ): Promise<any[]> {\r\n    try {\r\n      console.log(`Searching ${dataStoreIds.length} data stores with query embedding`);\r\n      \r\n      // For now, we'll use a simplified approach since Vertex AI Vector Search\r\n      // requires additional setup and configuration\r\n      // In production, you would use the Vertex AI Vector Search API directly\r\n      \r\n      // Simulate vector search results based on the query embedding\r\n      // This would be replaced with actual vector search API calls\r\n      const mockResults = [\r\n        {\r\n          id: \"doc-001\",\r\n          content: \"This research paper discusses the latest developments in machine learning algorithms and their applications in various domains. The study presents novel approaches to neural network optimization and demonstrates significant improvements in model performance across multiple benchmarks.\",\r\n          metadata: {\r\n            paperId: \"paper-001\",\r\n            title: \"Recent Advances in Machine Learning\",\r\n            authors: [\"Dr. Jane Smith\", \"Prof. John Doe\"],\r\n            pageNumber: 1,\r\n            score: 0.95,\r\n            dataStoreId: dataStoreIds[0],\r\n          }\r\n        },\r\n        {\r\n          id: \"doc-002\",\r\n          content: \"The study presents a comprehensive analysis of neural network architectures and their performance characteristics. Results show that transformer-based models outperform traditional approaches in natural language processing tasks.\",\r\n          metadata: {\r\n            paperId: \"paper-002\",\r\n            title: \"Neural Network Analysis\",\r\n            authors: [\"Dr. Michael Johnson\"],\r\n            pageNumber: 3,\r\n            score: 0.87,\r\n            dataStoreId: dataStoreIds[0],\r\n          }\r\n        }\r\n      ];\r\n\r\n      // Filter results based on data store scope\r\n      return mockResults.filter(result => \r\n        dataStoreIds.includes(result.metadata.dataStoreId)\r\n      );\r\n    } catch (error) {\r\n      console.error(\"Error searching vector store:\", error);\r\n      throw new Error(\"Failed to search vector store\");\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Prepare context from search results\r\n   */\r\n  private prepareContext(searchResults: any[]): string {\r\n    if (searchResults.length === 0) {\r\n      return \"No relevant documents found in the knowledge base.\";\r\n    }\r\n\r\n    return searchResults\r\n      .map((result, index) => {\r\n        const metadata = result.metadata;\r\n        return `[${index + 1}] ${result.content}\\nSource: ${metadata.title} by ${metadata.authors.join(', ')} (Page ${metadata.pageNumber})`;\r\n      })\r\n      .join('\\n\\n');\r\n  }\r\n\r\n  /**\r\n   * Generate answer using Gemini model\r\n   */\r\n  private async generateAnswer(\r\n    query: string, \r\n    context: string, \r\n    searchResults: any[]\r\n  ): Promise<string> {\r\n    try {\r\n      const model = \"gemini-1.5-flash-001\";\r\n      const endpoint = `${this.endpoint}/publishers/google/models/${model}`;\r\n      \r\n      const prompt = `You are a research assistant helping with academic queries. \r\n      \r\nBased on the following context from research papers, please answer the user's question. \r\nProvide a comprehensive, well-structured response that synthesizes information from the sources.\r\n\r\nUser Question: ${query}\r\n\r\nContext from research papers:\r\n${context}\r\n\r\nInstructions:\r\n- Answer the question based on the provided context\r\n- Cite the sources using [1], [2], etc. format\r\n- If the context doesn't contain enough information to answer the question, say so\r\n- Provide a clear, academic-style response\r\n- Include key findings and insights from the sources\r\n- Be concise but thorough\r\n\r\nAnswer:`;\r\n\r\n      const request = {\r\n        endpoint,\r\n        instances: [\r\n          {\r\n            structValue: {\r\n              fields: {\r\n                content: {\r\n                  structValue: {\r\n                    fields: {\r\n                      parts: {\r\n                        listValue: {\r\n                          values: [\r\n                            {\r\n                              structValue: {\r\n                                fields: {\r\n                                  text: {\r\n                                    stringValue: prompt\r\n                                  }\r\n                                }\r\n                              }\r\n                            }\r\n                          ]\r\n                        }\r\n                      }\r\n                    }\r\n                  }\r\n                }\r\n              }\r\n            }\r\n          }\r\n        ],\r\n        parameters: {\r\n          structValue: {\r\n            fields: {\r\n              temperature: { numberValue: 0.3 },\r\n              maxOutputTokens: { numberValue: 1024 },\r\n              topP: { numberValue: 0.8 },\r\n              topK: { numberValue: 40 },\r\n            }\r\n          }\r\n        },\r\n      };\r\n\r\n      const [response] = await this.client.predict(request);\r\n      const prediction = response.predictions?.[0];\r\n      \r\n      if (!prediction || !prediction.structValue?.fields?.content?.structValue?.fields?.parts?.listValue?.values?.[0]?.structValue?.fields?.text?.stringValue) {\r\n        throw new Error(\"Failed to generate answer\");\r\n      }\r\n\r\n      const answer = prediction.structValue.fields.content.structValue.fields.parts.listValue.values[0].structValue.fields.text.stringValue;\r\n      return answer;\r\n\r\n    } catch (error) {\r\n      console.error(\"Error generating answer:\", error);\r\n      throw new Error(\"Failed to generate answer\");\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Format search results as sources\r\n   */\r\n  private formatSources(searchResults: any[]): Source[] {\r\n    return searchResults.map(result => ({\r\n      paperId: result.metadata.paperId,\r\n      title: result.metadata.title,\r\n      authors: result.metadata.authors,\r\n      pageNumber: result.metadata.pageNumber,\r\n      content: result.content,\r\n      score: result.metadata.score,\r\n    }));\r\n  }\r\n\r\n  /**\r\n   * Ingest document chunks into Vertex AI Search\r\n   */\r\n  async ingestDocument(\r\n    dataStoreId: string,\r\n    chunks: Array<{\r\n      content: string;\r\n      metadata: Record<string, any>;\r\n    }>\r\n  ): Promise<void> {\r\n    try {\r\n      console.log(`Ingesting ${chunks.length} chunks into data store: ${dataStoreId}`);\r\n      \r\n      // 1. Generate embeddings for each chunk\r\n      const embeddings = await Promise.all(\r\n        chunks.map(chunk => this.generateEmbedding(chunk.content))\r\n      );\r\n      \r\n      // 2. Create documents in Vertex AI Search format\r\n      const documents = chunks.map((chunk, index) => ({\r\n        id: `${dataStoreId}-${Date.now()}-${index}`,\r\n        content: chunk.content,\r\n        embedding: embeddings[index],\r\n        metadata: {\r\n          ...chunk.metadata,\r\n          dataStoreId,\r\n          ingestedAt: new Date().toISOString(),\r\n        },\r\n      }));\r\n      \r\n      // 3. Upload to Vertex AI Search\r\n      await this.uploadToVectorSearch(dataStoreId, documents);\r\n      \r\n      console.log(`Successfully ingested ${chunks.length} chunks into ${dataStoreId}`);\r\n    } catch (error) {\r\n      console.error(\"Error ingesting document:\", error);\r\n      throw new Error(\"Failed to ingest document\");\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Upload documents to Vertex AI Search\r\n   * This is a placeholder for the actual Vertex AI Search API integration\r\n   */\r\n  private async uploadToVectorSearch(dataStoreId: string, documents: any[]): Promise<void> {\r\n    // In production, this would use the Vertex AI Search API\r\n    // For now, we'll simulate the upload process\r\n    console.log(`Uploading ${documents.length} documents to Vertex AI Search data store: ${dataStoreId}`);\r\n    \r\n    // Simulate processing time\r\n    await new Promise(resolve => setTimeout(resolve, 1000));\r\n    \r\n    console.log(`Successfully uploaded documents to ${dataStoreId}`);\r\n  }\r\n\r\n  /**\r\n   * Get data stores to query based on scope\r\n   */\r\n  private getDataStoresForScope(scope: string): string[] {\r\n    switch (scope) {\r\n      case \"private\":\r\n        return [\"user-private-datastore\"];\r\n      case \"public\":\r\n        return [\"public-research-datastore\"];\r\n      case \"all\":\r\n        return [\"user-private-datastore\", \"public-research-datastore\"];\r\n      default:\r\n        return [\"user-private-datastore\"];\r\n    }\r\n  }\r\n} ","import { ExecutionsClient } from \"@google-cloud/workflows\";\r\n\r\nexport class WorkflowsClient {\r\n  private client: ExecutionsClient;\r\n  private projectId: string;\r\n  private location: string;\r\n\r\n  constructor(projectId: string, location: string = \"us-central1\") {\r\n    this.client = new ExecutionsClient();\r\n    this.projectId = projectId;\r\n    this.location = location;\r\n  }\r\n\r\n  /**\r\n   * Trigger a document processing workflow\r\n   */\r\n  async triggerDocumentProcessing(workflowId: string, input: {\r\n    paperId: string;\r\n    storagePath: string;\r\n    userId: string;\r\n  }): Promise<string> {\r\n    try {\r\n      const parent = this.client.workflowPath(this.projectId, this.location, workflowId);\r\n      \r\n      const [execution] = await this.client.createExecution({\r\n        parent,\r\n        execution: {\r\n          argument: JSON.stringify(input),\r\n        },\r\n      });\r\n\r\n      console.log(`Created execution: ${execution.name}`);\r\n      return execution.name || \"\";\r\n    } catch (error) {\r\n      console.error(\"Error triggering workflow:\", error);\r\n      throw new Error(\"Failed to trigger document processing workflow\");\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get the status of a workflow execution\r\n   */\r\n  async getExecutionStatus(executionName: string): Promise<{\r\n    state: string;\r\n    result?: any;\r\n    error?: any;\r\n  }> {\r\n    try {\r\n      const [execution] = await this.client.getExecution({\r\n        name: executionName,\r\n      });\r\n\r\n      return {\r\n        state: String(execution.state || \"UNKNOWN\"),\r\n        result: execution.result ? JSON.parse(execution.result) : undefined,\r\n        error: execution.error ? JSON.stringify(execution.error) : undefined,\r\n      };\r\n    } catch (error) {\r\n      console.error(\"Error getting execution status:\", error);\r\n      throw new Error(\"Failed to get execution status\");\r\n    }\r\n  }\r\n} "],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA,wBAAwC;AAGjC,IAAM,iBAAN,MAAqB;AAAA,EAM1B,YAAY,WAAmB,WAAmB,eAAe;AAC/D,SAAK,SAAS,IAAI,0CAAwB;AAC1C,SAAK,YAAY;AACjB,SAAK,WAAW;AAChB,SAAK,WAAW,YAAY,SAAS,cAAc,QAAQ;AAAA,EAC7D;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,OAA4C;AACzD,QAAI;AACF,cAAQ,IAAI,8BAA8B,MAAM,KAAK,aAAa,MAAM,KAAK,GAAG;AAGhF,YAAM,iBAAiB,MAAM,KAAK,kBAAkB,MAAM,KAAK;AAG/D,YAAM,aAAa,KAAK,sBAAsB,MAAM,KAAK;AACzD,YAAM,gBAAgB,MAAM,KAAK,kBAAkB,gBAAgB,UAAU;AAG7E,YAAM,UAAU,KAAK,eAAe,aAAa;AAGjD,YAAM,SAAS,MAAM,KAAK,eAAe,MAAM,OAAO,SAAS,aAAa;AAG5E,YAAM,UAAU,KAAK,cAAc,aAAa;AAEhD,aAAO;AAAA,QACL;AAAA,QACA;AAAA,MACF;AAAA,IACF,SAAS,OAAO;AACd,cAAQ,MAAM,8BAA8B,KAAK;AACjD,YAAM,IAAI,MAAM,4BAA4B;AAAA,IAC9C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,kBAAkB,MAAiC;AAC/D,QAAI;AACF,YAAM,QAAQ;AACd,YAAM,WAAW,GAAG,KAAK,QAAQ,6BAA6B,KAAK;AAEnE,YAAM,UAAU;AAAA,QACd;AAAA,QACA,WAAW;AAAA,UACT;AAAA,YACE,aAAa;AAAA,cACX,QAAQ;AAAA,gBACN,SAAS;AAAA,kBACP,aAAa;AAAA,gBACf;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAEA,YAAM,CAAC,QAAQ,IAAI,MAAM,KAAK,OAAO,QAAQ,OAAO;AACpD,YAAM,aAAa,SAAS,cAAc,CAAC;AAE3C,UAAI,CAAC,cAAc,CAAC,WAAW,aAAa,QAAQ,YAAY,aAAa,QAAQ,QAAQ,WAAW,QAAQ;AAC9G,cAAM,IAAI,MAAM,8BAA8B;AAAA,MAChD;AAEA,YAAM,kBAAkB,WAAW,YAAY,OAAO,WAAW,YAAY,OAAO,OAAO,UAAU;AACrG,aAAO,gBAAgB,IAAI,CAAC,UAAe,MAAM,eAAe,CAAC;AAAA,IAEnE,SAAS,OAAO;AACd,cAAQ,MAAM,+BAA+B,KAAK;AAClD,YAAM,IAAI,MAAM,mCAAmC;AAAA,IACrD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,kBACZ,gBACA,cACgB;AAChB,QAAI;AACF,cAAQ,IAAI,aAAa,aAAa,MAAM,mCAAmC;AAQ/E,YAAM,cAAc;AAAA,QAClB;AAAA,UACE,IAAI;AAAA,UACJ,SAAS;AAAA,UACT,UAAU;AAAA,YACR,SAAS;AAAA,YACT,OAAO;AAAA,YACP,SAAS,CAAC,kBAAkB,gBAAgB;AAAA,YAC5C,YAAY;AAAA,YACZ,OAAO;AAAA,YACP,aAAa,aAAa,CAAC;AAAA,UAC7B;AAAA,QACF;AAAA,QACA;AAAA,UACE,IAAI;AAAA,UACJ,SAAS;AAAA,UACT,UAAU;AAAA,YACR,SAAS;AAAA,YACT,OAAO;AAAA,YACP,SAAS,CAAC,qBAAqB;AAAA,YAC/B,YAAY;AAAA,YACZ,OAAO;AAAA,YACP,aAAa,aAAa,CAAC;AAAA,UAC7B;AAAA,QACF;AAAA,MACF;AAGA,aAAO,YAAY;AAAA,QAAO,YACxB,aAAa,SAAS,OAAO,SAAS,WAAW;AAAA,MACnD;AAAA,IACF,SAAS,OAAO;AACd,cAAQ,MAAM,iCAAiC,KAAK;AACpD,YAAM,IAAI,MAAM,+BAA+B;AAAA,IACjD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,eAAe,eAA8B;AACnD,QAAI,cAAc,WAAW,GAAG;AAC9B,aAAO;AAAA,IACT;AAEA,WAAO,cACJ,IAAI,CAAC,QAAQ,UAAU;AACtB,YAAM,WAAW,OAAO;AACxB,aAAO,IAAI,QAAQ,CAAC,KAAK,OAAO,OAAO;AAAA,UAAa,SAAS,KAAK,OAAO,SAAS,QAAQ,KAAK,IAAI,CAAC,UAAU,SAAS,UAAU;AAAA,IACnI,CAAC,EACA,KAAK,MAAM;AAAA,EAChB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,eACZ,OACA,SACA,eACiB;AACjB,QAAI;AACF,YAAM,QAAQ;AACd,YAAM,WAAW,GAAG,KAAK,QAAQ,6BAA6B,KAAK;AAEnE,YAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,iBAKJ,KAAK;AAAA;AAAA;AAAA,EAGpB,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAYH,YAAM,UAAU;AAAA,QACd;AAAA,QACA,WAAW;AAAA,UACT;AAAA,YACE,aAAa;AAAA,cACX,QAAQ;AAAA,gBACN,SAAS;AAAA,kBACP,aAAa;AAAA,oBACX,QAAQ;AAAA,sBACN,OAAO;AAAA,wBACL,WAAW;AAAA,0BACT,QAAQ;AAAA,4BACN;AAAA,8BACE,aAAa;AAAA,gCACX,QAAQ;AAAA,kCACN,MAAM;AAAA,oCACJ,aAAa;AAAA,kCACf;AAAA,gCACF;AAAA,8BACF;AAAA,4BACF;AAAA,0BACF;AAAA,wBACF;AAAA,sBACF;AAAA,oBACF;AAAA,kBACF;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,QACA,YAAY;AAAA,UACV,aAAa;AAAA,YACX,QAAQ;AAAA,cACN,aAAa,EAAE,aAAa,IAAI;AAAA,cAChC,iBAAiB,EAAE,aAAa,KAAK;AAAA,cACrC,MAAM,EAAE,aAAa,IAAI;AAAA,cACzB,MAAM,EAAE,aAAa,GAAG;AAAA,YAC1B;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAEA,YAAM,CAAC,QAAQ,IAAI,MAAM,KAAK,OAAO,QAAQ,OAAO;AACpD,YAAM,aAAa,SAAS,cAAc,CAAC;AAE3C,UAAI,CAAC,cAAc,CAAC,WAAW,aAAa,QAAQ,SAAS,aAAa,QAAQ,OAAO,WAAW,SAAS,CAAC,GAAG,aAAa,QAAQ,MAAM,aAAa;AACvJ,cAAM,IAAI,MAAM,2BAA2B;AAAA,MAC7C;AAEA,YAAM,SAAS,WAAW,YAAY,OAAO,QAAQ,YAAY,OAAO,MAAM,UAAU,OAAO,CAAC,EAAE,YAAY,OAAO,KAAK;AAC1H,aAAO;AAAA,IAET,SAAS,OAAO;AACd,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC7C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,cAAc,eAAgC;AACpD,WAAO,cAAc,IAAI,aAAW;AAAA,MAClC,SAAS,OAAO,SAAS;AAAA,MACzB,OAAO,OAAO,SAAS;AAAA,MACvB,SAAS,OAAO,SAAS;AAAA,MACzB,YAAY,OAAO,SAAS;AAAA,MAC5B,SAAS,OAAO;AAAA,MAChB,OAAO,OAAO,SAAS;AAAA,IACzB,EAAE;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,eACJ,aACA,QAIe;AACf,QAAI;AACF,cAAQ,IAAI,aAAa,OAAO,MAAM,4BAA4B,WAAW,EAAE;AAG/E,YAAM,aAAa,MAAM,QAAQ;AAAA,QAC/B,OAAO,IAAI,WAAS,KAAK,kBAAkB,MAAM,OAAO,CAAC;AAAA,MAC3D;AAGA,YAAM,YAAY,OAAO,IAAI,CAAC,OAAO,WAAW;AAAA,QAC9C,IAAI,GAAG,WAAW,IAAI,KAAK,IAAI,CAAC,IAAI,KAAK;AAAA,QACzC,SAAS,MAAM;AAAA,QACf,WAAW,WAAW,KAAK;AAAA,QAC3B,UAAU;AAAA,UACR,GAAG,MAAM;AAAA,UACT;AAAA,UACA,aAAY,oBAAI,KAAK,GAAE,YAAY;AAAA,QACrC;AAAA,MACF,EAAE;AAGF,YAAM,KAAK,qBAAqB,aAAa,SAAS;AAEtD,cAAQ,IAAI,yBAAyB,OAAO,MAAM,gBAAgB,WAAW,EAAE;AAAA,IACjF,SAAS,OAAO;AACd,cAAQ,MAAM,6BAA6B,KAAK;AAChD,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC7C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAc,qBAAqB,aAAqB,WAAiC;AAGvF,YAAQ,IAAI,aAAa,UAAU,MAAM,8CAA8C,WAAW,EAAE;AAGpG,UAAM,IAAI,QAAQ,aAAW,WAAW,SAAS,GAAI,CAAC;AAEtD,YAAQ,IAAI,sCAAsC,WAAW,EAAE;AAAA,EACjE;AAAA;AAAA;AAAA;AAAA,EAKQ,sBAAsB,OAAyB;AACrD,YAAQ,OAAO;AAAA,MACb,KAAK;AACH,eAAO,CAAC,wBAAwB;AAAA,MAClC,KAAK;AACH,eAAO,CAAC,2BAA2B;AAAA,MACrC,KAAK;AACH,eAAO,CAAC,0BAA0B,2BAA2B;AAAA,MAC/D;AACE,eAAO,CAAC,wBAAwB;AAAA,IACpC;AAAA,EACF;AACF;;;AC5UA,uBAAiC;AAE1B,IAAM,kBAAN,MAAsB;AAAA,EAK3B,YAAY,WAAmB,WAAmB,eAAe;AAC/D,SAAK,SAAS,IAAI,kCAAiB;AACnC,SAAK,YAAY;AACjB,SAAK,WAAW;AAAA,EAClB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,0BAA0B,YAAoB,OAIhC;AAClB,QAAI;AACF,YAAM,SAAS,KAAK,OAAO,aAAa,KAAK,WAAW,KAAK,UAAU,UAAU;AAEjF,YAAM,CAAC,SAAS,IAAI,MAAM,KAAK,OAAO,gBAAgB;AAAA,QACpD;AAAA,QACA,WAAW;AAAA,UACT,UAAU,KAAK,UAAU,KAAK;AAAA,QAChC;AAAA,MACF,CAAC;AAED,cAAQ,IAAI,sBAAsB,UAAU,IAAI,EAAE;AAClD,aAAO,UAAU,QAAQ;AAAA,IAC3B,SAAS,OAAO;AACd,cAAQ,MAAM,8BAA8B,KAAK;AACjD,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,mBAAmB,eAItB;AACD,QAAI;AACF,YAAM,CAAC,SAAS,IAAI,MAAM,KAAK,OAAO,aAAa;AAAA,QACjD,MAAM;AAAA,MACR,CAAC;AAED,aAAO;AAAA,QACL,OAAO,OAAO,UAAU,SAAS,SAAS;AAAA,QAC1C,QAAQ,UAAU,SAAS,KAAK,MAAM,UAAU,MAAM,IAAI;AAAA,QAC1D,OAAO,UAAU,QAAQ,KAAK,UAAU,UAAU,KAAK,IAAI;AAAA,MAC7D;AAAA,IACF,SAAS,OAAO;AACd,cAAQ,MAAM,mCAAmC,KAAK;AACtD,YAAM,IAAI,MAAM,gCAAgC;AAAA,IAClD;AAAA,EACF;AACF;","names":[]}